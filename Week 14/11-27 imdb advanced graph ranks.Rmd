---
title: 'R Notebook: IMDB (predict gender from biography)'
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    toc_depth: 5
    fig_caption: true
    number_sections: true 
---

```{r}

library(devtools);

library(humanVerseWSU);

path.github = "https://raw.githubusercontent.com/MonteShaffer/humanVerseWSU/master/";

include.me = paste0(path.github, "misc/functions-nlp.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-str.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-stack.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-pos.R");
source_url( include.me );

include.me = paste0(path.github, "humanVerseWSU/R/functions-encryption.R");
source_url( include.me );



path.to.nascent = "C:/Users/Alexander Nevsky/Dropbox/WSU-419/Fall 2020/__student_access__/unit_02_confirmatory_data_analysis/nascent/";

folder.nlp = "nlp/";
path.to.nlp = paste0(path.to.nascent, folder.nlp);


###### UPDATES TO dataframe subset function ######
# inflation adjustments for NA ... and improvements on subsetting
include.me = paste0(path.github, "humanVerseWSU/R/functions-dataframe.R");
source_url( include.me );

include.me = paste0(path.github, "humanVerseWSU/R/functions-inflation.R");
source_url( include.me );

```

# (IMDB) Social Network

## IMDB data

Back to the research question, after a bit of a detour.  Can we apply this method to ascertain the "rank" of movies and actors.  Let's give it a try.  First, remember, we need an adjacency matrix, with movies-linking-to-movies or actors-linking-to-actors.  It needs to be row/col symmetric in form (although the elements of the matrix do not need to be symmetric).

We don't have that form yet.  We can build a matrix with actors in the rows and movies in the columns; or vice versa.  So what can we do.

### Build the relationships of actors-movies

Choosing how to define (or truncate the matrix) may influence the results, but not by much.  A dud movie/actor will still be a dud.

So let's take the new movie-actor collection and build a matrix.  For now, we will only place a binary value (0 or 1) to represent a link between an actor and a movie.  We may later weight the values based on being a headliner or a director or whatever.

```{r}
library(imdb);
packageVersion("imdb");  # ‘0.1.1’

imdb::loadDataIMDB();
names(imdb.data);
```

```{r}
network = imdb.data$movies.df$cast;
dim(network);
names(network);

n.ttid = length(unique(network$ttid));
n.nmid = length(unique(network$nmid));

my.ttids = sort( unique(network$ttid) );
my.nmids = sort( unique(network$nmid) );
```
We have a network of 10,193 movies and 64,666 actors (not including creatives).  This is a big matrix, but is likely sparse ... let's see if R can handle it as-is.  If not, there are "sparse-matrix" techniques we could utilize.

I call the matrix "AM" actors for rows, movies for columns.

```{r}
# AM = matrix(0, nrow=n.nmid, ncol=n.ttid);
#   rownames(A) = my.nmids;
#   colnames(A) = my.ttids;
# dim(AM);
# AM[1:10,1:5];
```
This next step will be time-consuming... We have to loop through each record of the network cast dataframe, grab the ttid and nmid, figure out the corresponding row/col and populate with a 1.

We only have 120,678 entries and our matrix is 64666 * 10193 = 659,140,538 elements.  That is 0.0183% sparse.

```{r}
# nrow = nrow(network);
# nrow;
# 
# for(i in 1:nrow)
#   {
#   if(i %% 25000 == 1) { print(i); flush.console();}
#   row = network[i,];
#   ttid = row$ttid;
#   nmid = row$nmid;
#   
#   r = which(my.nmids == nmid);
#   c = which(my.ttids == ttid);
#   AM[r,c] = 1;
#   }
# 
# sum(AM);
```

### AA from AM

I can build an actor-actor matrix by multiplying the AM matrix by its transpose.

```{r}
# AA = AM %*% t(AM);
# dim(AA);
```


### MM from AM

I can build an actor-actor matrix by multiplying the AM matrix by its transpose.

```{r}
# MM = t(AM) %*% (AM);
# dim(MM);
```


I am going to augment to the last row, easier to accomplish.


## IMDB data (v 2)
Based on a night's sleep and the video on advanced feature, I want to prevent "gaming" by creating a level playing field.  Increasing N and introducing randomness is how you game PageRank; the patent network makes such gaming more challening and expensive, but possible (e.g., Canon's inkjet printers).  

If we use the top50 as the key for the network, it is constrained and the links are within the "best" as defined by popular50.

We expected WILL to have 19 movies, it appears he has 16; we expected DENZEL to have 19 movies, it appears he has 18.



```{r}
# library(imdb);
# packageVersion("imdb");  # ‘0.1.1’
# 
# imdb::loadDataIMDB();
# names(imdb.data);
```

```{r}
df = subsetDataFrame(imdb.data$movies$popular50, "year", ">=", 1980);
df = subsetDataFrame(df, "year", "<", 2020);
ttids = df$ttid;
dim(df);
```

```{r}
df.cast = merge(df, imdb.data$movies.df$cast, by="ttid");
dim(df.cast);
length(unique(df.cast$ttid));
length(unique(df.cast$nmid));
```
We have a full dataset, about 2000 movies and 29,601 actor-links.  We have about 17,150 unique actors.

```{r}
network = df.cast;
n.ttid = length(unique(network$ttid));
n.nmid = length(unique(network$nmid));

my.ttids = sort( unique(network$ttid) );
my.nmids = sort( unique(network$nmid) );
```


```{r}
AM = matrix(0, nrow=n.nmid, ncol=n.ttid);
  rownames(AM) = my.nmids;
  colnames(AM) = my.ttids;
dim(AM);
AM[1:10,1:5];
```

We only have 29,601 entries and our matrix is 17149 * 1998 = 34,263,702 elements.  That is 0.0863% sparse.

```{r}
nrow = nrow(network);
nrow;

for(i in 1:nrow)
  {
  if(i %% 25000 == 1) { print(i); flush.console();}
  row = network[i,];
  ttid = row$ttid;
  nmid = row$nmid;

  r = which(my.nmids == nmid);
  c = which(my.ttids == ttid);
  AM[r,c] = 1;
  }

sum(AM);
```

### AA from AM

I can build an actor-actor matrix by multiplying the AM matrix by its transpose.

```{r}
# timer.start = as.numeric(Sys.time());
# AA = AM %*% t(AM);
# timer.end = as.numeric(Sys.time());
# elapsed = round(timer.end - timer.start,2);
# print(paste0("Time: ", elapsed, " secs"));  # "Time: 392.57 secs"
# dim(AA);
```


### MM from AM

I can build an actor-actor matrix by multiplying the AM matrix by its transpose.

```{r}
# timer.start = as.numeric(Sys.time());
# MM = t(AM) %*% (AM);
# timer.end = as.numeric(Sys.time());
# elapsed = round(timer.end - timer.start,2);
# print(paste0("Time: ", elapsed, " secs")); # "Time: 45.83 secs"
# dim(MM); 
```

### CPP for SPEED
<https://stackoverflow.com/questions/35923787/fast-large-matrix-multiplication-in-r?noredirect=1&lq=1>

I have used "Eigen" before to do this matrix math.  We are still struggling with base-R, so let's try and see if we can speed things up.

```{r}
# include.me = paste0(path.github, "humanVerseWSU/R/functions-file.R");
# source_url( include.me );
# this.path = getDirectoryOfThisFile();  # will work in RStudio
# setwd(this.path);
this.path = path.to.nascent;
setwd(this.path);

# Requires Rtools on Windoze
# install.packages("RcppEigen", type="source");
# install.packages("RcppArmadillo", type="source");

library(Rcpp)

A <- matrix(rnorm(10000), 100, 100) # fully populated, 100 x 100, relatively small
B <- matrix(rnorm(10000), 100, 100)

library(microbenchmark)
# I added "Trans" for Matrix Transpose to this example code.
sourceCpp("multiply.cpp")
microbenchmark(eigenMatTrans(A),A%*%B, armaMatMult(A, B), eigenMatMult(A, B), eigenMapMatMult(A, B))

```

### AAM from AM (C++)

I need a transpose as well: <https://eigen.tuxfamily.org/dox/classEigen_1_1Transpose.html>

```{r}
timer.start = as.numeric(Sys.time());
# AA = AM %*% t(AM);
AM.t = eigenMatTrans(AM);
AA = eigenMatMult(AM, AM.t);
rownames(AA) = colnames(AA) = my.nmids;
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs"));  # "Time: 392.57 secs"
dim(AA);
```
C++ took it from 392 seconds (6.5 minutes) to 15 seconds.  ["Time: 14.8 secs"] ... 26.5 times faster ...


## ActorRank

### Augment the matrix

For simplicity, I will augment at the end, rather than the beginning.

I will also make certain an actor doesn't link to its own node, diagonal is zero.

```{r}
rownames(AA) = colnames(AA) = my.nmids;
n.nmids = length(my.nmids);

# run this augment only once ...
AA=rbind(AA,1);
AA=cbind(AA,1);
AA[(n.nmids+1),(n.nmids+1)] = 0;
diag(AA) = 0;

round(AA[((n.nmids+1-5):(n.nmids+1)),((n.nmids+1-5):(n.nmids+1))],2);
```

### Row normalize
Now I will row normalize ...

```{r}
AAn = AA / rowSums(AA);
round(AAn[((n.nmids+1-5):(n.nmids+1)),((n.nmids+1-5):(n.nmids+1))],2);
```

### Power Computation

```{r}
matrixPowerC = function(AA,times=1)
  {
  for(i in 1:times)
    {
    AA = eigenMatMult(AA, AA);
    }
  AA;
  }

timer.start = as.numeric(Sys.time());
AAnp = matrixPowerC(AAn, 8); # let's hope 8 is enough for convergence
# about 6 minutes? ...  [1] "Time: 735.3 secs"
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs"));
```


### Best actors of this era?

```{r}
actorRank = AAnp[1,-c((n.nmids+1))]; # any row, less the supernode, which will have a very large value...
  names(actorRank) = my.nmids;
actorRank = sort((100*actorRank/max(actorRank)),decreasing=TRUE);
# head(actorRank,50);

actorRank.df = as.data.frame( cbind( names(actorRank), as.numeric(actorRank) ));
colnames(actorRank.df) = c("nmid", "actorRank");
actorRank.df$actorRank = round(as.numeric(actorRank.df$actorRank),2);


actorRank.df = merge(actorRank.df, imdb.data$all.actors.info, by="nmid");


actorRank.df = sortDataFrameByNumericColumns(actorRank.df, "actorRank", "DESC");

names(actorRank.df); # lots of columns here
actorRank.df[,c(2,3,1,4)];

this.path = path.to.nascent;
setwd(this.path);
saveRDS(actorRank.df, "actorRank2000.rds");
```














```{r}
timer.start = as.numeric(Sys.time());
# MM = t(AM) %*% (AM);
MM = eigenMatMult(AM.t, AM);
rownames(MM) = colnames(MM) = my.ttids;
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs")); # "Time: 45.83 secs"
dim(MM);
```

C++ took it from 46 seconds to 2 seconds.  ["Time: 14.8 secs"] ... 21 times faster ...


## Will Smith first-contacts, zero-degrees of separation
```{r}
nmid = "nm0000226";
idx = which(rownames(AA)==nmid);

AA.r = AA[idx,];

idx0 = which(AA.r == 0);

AA.rs = sort(AA.r[-c(idx0,idx)], decreasing=TRUE); # remove zeroes and self

length(AA.rs);  # number of unique actors
sum(AA.rs);  # total ties.  one actor may be higher than another

head(AA.rs,10);
```


### Denzel Washington first-contacts, zero-degrees of separation
```{r}
nmid = "nm0000243";
idx = which(rownames(AA)==nmid);

AA.r = AA[idx,];

idx0 = which(AA.r == 0);

AA.rs = sort(AA.r[-c(idx0,idx)], decreasing=TRUE); # remove zeroes and self

length(AA.rs);  # number of unique actors
sum(AA.rs);  # total ties.  one actor may be higher than another

head(AA.rs,10);
```
Remember, this is a limited network of actors linked to these 2000 movies.

### N - degrees of freedom
This is a largish matrix, will take some time.
```{r}
timer.start = as.numeric(Sys.time());
AA.1 = eigenMatMult(AA, AA); # one degree of separation
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs"));
```

```{r}
timer.start = as.numeric(Sys.time());
AA.2 = eigenMatMult(AA.1, AA); # two degrees of separation
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs"));
```



```{r}
nmid1 = "nm0000243"; # denzel
nmid2 = "nm0000226"; # will smith

numberMoviesShared = function(nmid1, nmid2, AA)
  {
  
  }


```


## IMDB data (v 3)
I am going to go back to the full dataset I have developed.  It will offer a different "scale" to review actorRank and movieRank.  

```{r}
library(imdb);
packageVersion("imdb");  # ‘0.1.1’

imdb::loadDataIMDB();
names(imdb.data);
```


```{r}
network = merge(imdb.data$movies.df$cast, imdb.data$movies$popular50, by="ttid");
dim(network);
names(network);


my.ttids = sort( unique(network$ttid) );
my.nmids = sort( unique(network$nmid) );

n.ttid = length(unique(network$ttid));
n.nmid = length(unique(network$nmid));


```


```{r}
AM = matrix(0, nrow=n.nmid, ncol=n.ttid);
  rownames(AM) = my.nmids;
  colnames(AM) = my.ttids;
dim(AM);
AM[1:10,1:5];
```


```{r}
nrow = nrow(network);
nrow;

for(i in 1:nrow)
  {
  if(i %% 25000 == 1) { print(i); flush.console();}
  row = network[i,];
  ttid = row$ttid;
  nmid = row$nmid;

  r = which(my.nmids == nmid);
  c = which(my.ttids == ttid);
  AM[r,c] = 1;
  }

sum(AM);
```


```{r}
this.path = path.to.nascent;
setwd(this.path);
library(Rcpp);
# I added "Trans" for Matrix Transpose to this example code.
sourceCpp("multiply.cpp");
```

# Actors :: 35245 from top 5000 (movies)

```{r}
timer.start = as.numeric(Sys.time());
# AA = AM %*% t(AM);
AM.t = eigenMatTrans(AM);
AA = eigenMatMult(AM, AM.t);
rownames(AA) = colnames(AA) = my.nmids;
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs"));  "Time: 1109.9 secs"
dim(AA);
```



```{r}
rownames(AA) = colnames(AA) = my.nmids;
n.nmids = length(my.nmids);

# run this augment only once ...
AA=rbind(AA,1);
AA=cbind(AA,1);
AA[(n.nmids+1),(n.nmids+1)] = 0;
diag(AA) = 0;

round(AA[((n.nmids+1-5):(n.nmids+1)),((n.nmids+1-5):(n.nmids+1))],2);
```

### Row normalize
Now I will row normalize ...

```{r}
AAn = AA / rowSums(AA);
round(AAn[((n.nmids+1-5):(n.nmids+1)),((n.nmids+1-5):(n.nmids+1))],2);
```

### Power Computation

```{r}
matrixPowerC = function(AA,times=1)
  {
  for(i in 1:times)
    {
    print(i); flush.console();
    AA = eigenMatMult(AA, AA);
    }
  AA;
  }

timer.start = as.numeric(Sys.time());
AAnp = matrixPowerC(AAn, 8); # let's hope 8 is enough for convergence
# about 6 minutes? ...  [1] "Time: 735.3 secs"
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs"));
```


### Best actors of all time?

```{r}
actorRank = AAnp[1,-c((n.nmids+1))]; # any row, less the supernode, which will have a very large value...
  names(actorRank) = my.nmids;
actorRank = sort((100*actorRank/max(actorRank)),decreasing=TRUE);
# head(actorRank,50);

actorRank.df = as.data.frame( cbind( names(actorRank), as.numeric(actorRank) ));
colnames(actorRank.df) = c("nmid", "actorRank");
actorRank.df$actorRank = round(as.numeric(actorRank.df$actorRank),2);


actorRank.df = merge(actorRank.df, imdb.data$all.actors.info, by="nmid");


actorRank.df = sortDataFrameByNumericColumns(actorRank.df, "actorRank", "DESC");

names(actorRank.df); # lots of columns here
actorRank.df[,c(2,3,1,4)];

this.path = path.to.nascent;
setwd(this.path);
saveRDS(actorRank.df, "actorRank5000.rds");
```


# Movies :: top 5000





```{r}
timer.start = as.numeric(Sys.time());
# MM = t(AM) %*% (AM);
AM.t = eigenMatTrans(AM);
MM = eigenMatMult(AM.t,AM);
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs")); # "Time: 121.43 secs"
dim(MM);
```


```{r}
rownames(MM) = colnames(MM) = my.ttids;
n.ttids = length(my.ttids);

# run this augment only once ...
MM=rbind(MM,1);
MM=cbind(MM,1);
MM[(n.ttids+1),(n.ttids+1)] = 0;
diag(MM) = 0;

round(MM[((n.ttids+1-5):(n.ttids+1)),((n.ttids+1-5):(n.ttids+1))],2);
```

### Row normalize
Now I will row normalize ...

```{r}
MMn = MM / rowSums(MM);
round(MMn[((n.ttids+1-5):(n.ttids+1)),((n.ttids+1-5):(n.ttids+1))],2);
```

### Power Computation

```{r}
timer.start = as.numeric(Sys.time());
MMnp = matrixPowerC(MMn, 8); # let's hope 8 is enough for convergence
# about 6 minutes? ...
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2); # [1] "Time: 155.14 secs"
print(paste0("Time: ", elapsed, " secs"));
```

### Best movies of all time?

```{r}
movieRank = MMnp[1,-c((n.ttids+1))]; # any row, less the supernode, which will have a very large value...
  names(movieRank) = my.ttids;
movieRank = sort((100*movieRank/max(movieRank)),decreasing=TRUE);
# head(movieRank,50);

movieRank.df = as.data.frame( cbind( names(movieRank), as.numeric(movieRank) ));
colnames(movieRank.df) = c("ttid", "movieRank");
movieRank.df$movieRank = round(as.numeric(movieRank.df$movieRank),2);


movieRank.df = merge(movieRank.df, imdb.data$all.actors.movies, by="ttid");

movieRank.df = merge(movieRank.df, imdb.data$movies.df$info, by="ttid");

movieRank.df = sortDataFrameByNumericColumns(movieRank.df, "movieRank", "DESC");

names(movieRank.df); # lots of columns here
 movieRank.df[,c(2,3,4,1)];
subsetDataFrame(movieRank.df,"year", ">=", 1980)[,c(2,3,4,1)];

# this.path = path.to.nascent;
# setwd(this.path);
# saveRDS(movieRank.df, "movieRank5000.rds");
```



# -------OLD STUFF-------


## IMDB results

The matrix size is still causing an issue.  RStudio has to store a lot in RAM and doesn't like it.  So I will get it to run in RGui as a separate notebook.

### Ranking movies

We might be able to deal with the movies in RStudio without any help from C++ and RcppEigen.

```{r}
library(imdb);
packageVersion("imdb");  # ‘0.1.1’

imdb::loadDataIMDB();
names(imdb.data);
```

```{r}
df = subsetDataFrame(imdb.data$movies$popular50, "year", ">=", 1980);
df = subsetDataFrame(df, "year", "<", 2020);
ttids = df$ttid;
dim(df);

df.cast = merge(df, imdb.data$movies.df$cast, by="ttid");
dim(df.cast);
length(unique(df.cast$ttid));
length(unique(df.cast$nmid));

## we have the network we will analyze
network = df.cast;
n.ttid = length(unique(network$ttid));
n.nmid = length(unique(network$nmid));

my.ttids = sort( unique(network$ttid) );
my.nmids = sort( unique(network$nmid) );

AM = matrix(0, nrow=n.nmid, ncol=n.ttid);
  rownames(AM) = my.nmids;
  colnames(AM) = my.ttids;
dim(AM);
AM[1:10,1:5];

nrow = nrow(network);
nrow;
## we will populate all of the relationships
for(i in 1:nrow)
  {
  if(i %% 2500 == 1) { print(i); flush.console();}
  row = network[i,];
  ttid = row$ttid;
  nmid = row$nmid;

  r = which(my.nmids == nmid);
  c = which(my.ttids == ttid);
  AM[r,c] = 1;
  }
sum(AM);

## We will build MM a matrix of movies linked to movies (via actors).
timer.start = as.numeric(Sys.time());
MM = t(AM) %*% (AM);
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs")); # "Time: 45.83 secs"
dim(MM);
```

A movie has a direct link is an actor connects two movies together, this is "zero-degrees" of separation.  ``MM%*%MM`` would represent "one-degrees" of separation; ``MM%*%MM%*%MM`` would represent "two-degrees" of separation; and so on.

### Augment the matrix

For simplicity, I will augment at the end, rather than the beginning.

I will also make certain a movie doesn't cite itself, diagonal is zero.

```{r}
rownames(MM) = colnames(MM) = my.ttids;
n.ttids = length(my.ttids);

# run this augment only once ...
MM=rbind(MM,1);
MM=cbind(MM,1);
MM[(n.ttids+1),(n.ttids+1)] = 0;
diag(MM) = 0;

round(MM[((n.ttids+1-5):(n.ttids+1)),((n.ttids+1-5):(n.ttids+1))],2);
```

### Row normalize
Now I will row normalize ...

```{r}
MMn = MM / rowSums(MM);
round(MMn[((n.ttids+1-5):(n.ttids+1)),((n.ttids+1-5):(n.ttids+1))],2);
```

### Power Computation

```{r}
timer.start = as.numeric(Sys.time());
MMnp = matrixPower(MMn, 8); # let's hope 8 is enough for convergence
# about 6 minutes? ...
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs"));
```
### Best movies of this era?

```{r}
movieRank = MMnp[1,-c((n.ttids+1))]; # any row, less the supernode, which will have a very large value...
movieRank = sort((100*movieRank/max(movieRank)),decreasing=TRUE);
# head(movieRank,50);

movieRank.df = as.data.frame( cbind( names(movieRank), as.numeric(movieRank) ));
colnames(movieRank.df) = c("ttid", "movieRank");
movieRank.df$movieRank = round(as.numeric(movieRank.df$movieRank),2);


movieRank.df = merge(movieRank.df, imdb.data$all.actors.movies, by="ttid");

movieRank.df = merge(movieRank.df, imdb.data$movies.df$info, by="ttid");

movieRank.df = sortDataFrameByNumericColumns(movieRank.df, "movieRank", "DESC");

names(movieRank.df); # lots of columns here
movieRank.df[,c(2,4,1,3)];

this.path = path.to.nascent;
setwd(this.path);
saveRDS(movieRank.df, "movieRank2000.rds");
```

It is a challenge to argue with the top results.  However, there is a bit of gaming bias, since a large crew of actors appear on the same sequence of films.  So if a single movie has a large "n" of networks in the smaller network, they obviously inflate the result.  Equal "rank" scores means they have the exact same network structure.  If I included more data, it would show a more balanced picture and more unique scores.  But this is legit, based on the inputs, we are seeing top movies ranked by the "star power" on a given film.

We could use this result and see the movies that are linked to Will vs. Denzel.  Plus we can transform "money" to a common year and do rankings as discussed.  In this larger "pond" and see where Will vs Denzel fit.









